{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 1.0]\n",
      "[1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1]\n",
      "[[0.0, 0.0, 1.0, 1.0, 1.0, 0.0], [1.0, 1.0, 0.0, 1.0, 0.0, 1.0], [0.0, 1.0, 1.0, 0.0, 1.0, 0.0], [1.0, 0.0, 1.0, 1.0, 0.0, 1.0], [0.0, 1.0, 0.0, 1.0, 1.0, 0.0], [1.0, 0.0, 0.0, 1.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 1.0, 1.0], [1.0, 0.0, 1.0, 0.0, 1.0, 0.0], [0.0, 1.0, 1.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 1.0, 1.0, 0.0], [0.0, 1.0, 1.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 1.0, 0.0, 1.0], [1.0, 1.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 1.0, 0.0, 1.0], [1.0, 1.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 1.0, 1.0], [1.0, 1.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 1.0, 1.0, 0.0], [1.0, 1.0, 0.0, 1.0, 1.0, 1.0], [1.0, 0.0, 1.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 1.0, 1.0, 0.0], [1.0, 0.0, 1.0, 0.0, 1.0, 1.0], [0.0, 1.0, 0.0, 1.0, 0.0, 1.0], [1.0, 0.0, 1.0, 1.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 1.0, 1.0], [1.0, 0.0, 1.0, 0.0, 0.0, 1.0], [0.0, 1.0, 1.0, 1.0, 0.0, 1.0], [1.0, 0.0, 0.0, 1.0, 1.0, 1.0], [1.0, 1.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 1.0, 1.0], [1.0, 1.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 1.0, 1.0, 0.0], [1.0, 1.0, 0.0, 1.0, 0.0, 1.0]]\n"
     ]
    }
   ],
   "source": [
    "# Convert data from csv file to 2d list\n",
    "with open('dataset-6.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    data = []\n",
    "    for row in reader:\n",
    "        int_row = [float(x) for x in row]  # convert elements to integers\n",
    "        data.append(int_row)\n",
    "\n",
    "# print(data)\n",
    "\n",
    "# Separate features from labels\n",
    "features = [row[:len(row)-1] for row in data]\n",
    "\n",
    "unique_labels = list(set([row[-1] for row in data]))\n",
    "print(unique_labels)\n",
    "for i in data:\n",
    "    if i[-1] == unique_labels[0]:\n",
    "        i[-1] = 0\n",
    "    else:\n",
    "        i[-1] = 1\n",
    "\n",
    "labels = [row[-1] for row in data]\n",
    "\n",
    "print(labels)\n",
    "print(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly generate weights and threshold\n",
    "w_weight = [random.uniform(0, 1) for _ in range(len(features[0]))]\n",
    "threshold = 0.499\n",
    "gain_term = 0.69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9087493457386437,\n",
       " 0.37158873399866255,\n",
       " 0.05801833107801002,\n",
       " 0.5797665668277452,\n",
       " 0.7297384616574893,\n",
       " 0.8090576559912661]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.499"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gain_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_sum(input_pattern, w_weight):\n",
    "    \n",
    "    # Convert the input and weight array into numpy arrays\n",
    "    input_pattern = np.array(input_pattern)\n",
    "    w_weight = np.array(w_weight) \n",
    "\n",
    "    \n",
    "    # Return weighted sum for a particular pattern\n",
    "    return np.sum(np.multiply(input_pattern, w_weight))\n",
    "    \n",
    "\n",
    "# weighted_sum([1, 1, 1], w_weight)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(sum, threshold):\n",
    "    if sum < threshold:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1, -0.38999999999999996, -0.48999999999999994]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def adapt_weight(input_pattern, w_weight, error):\n",
    "    input_pattern = [item*error*gain_term for item in input_pattern]\n",
    "    new_weights = []\n",
    "    for weight, input in zip(w_weight, input_pattern):\n",
    "        new_weights.append(weight+input)\n",
    "    return new_weights\n",
    "\n",
    "    \n",
    "adapt_weight([0,1, 1], [.1, .3, .2], -1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_perceptron(features, labels, w_weight):\n",
    "    input_size = len(features)\n",
    "    new_weights = w_weight\n",
    "    for i in range(input_size):\n",
    "        weighted_output = weighted_sum(features[i], new_weights)\n",
    "        activated_output = step(weighted_output, threshold)\n",
    "        error = labels[i] - activated_output\n",
    "        # print(error)\n",
    "        if error!=0:\n",
    "            new_weights = adapt_weight(features[i], new_weights, error)\n",
    "            # print(new_weights)\n",
    "            \n",
    "            i = 0\n",
    "        \n",
    "            \n",
    "    return new_weights\n",
    "\n",
    "# start = timer()\n",
    "\n",
    "# w_weight = train_perceptron(X_train, y_train, w_weight)\n",
    "\n",
    "# end = timer()\n",
    "\n",
    "# print(\"Time taken for training: \", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9087493457386437,\n",
       " 0.37158873399866255,\n",
       " 0.05801833107801002,\n",
       " 0.5797665668277452,\n",
       " 0.7297384616574893,\n",
       " 0.8090576559912661]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_weight"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_perceptron(features, labels, w_weight):\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    \n",
    "    input_size = len(features)\n",
    "    new_weights = w_weight\n",
    "    for i in range(input_size):\n",
    "        weighted_output = weighted_sum(features[i], new_weights)\n",
    "        activated_output = step(weighted_output, threshold)\n",
    "\n",
    "        if activated_output == 0 and labels[i] == 0:\n",
    "            TN+=1\n",
    "        elif activated_output == 1 and labels[i] == 1:\n",
    "            TP+=1\n",
    "        elif activated_output == 0 and labels[i] == 1:\n",
    "            FN+=1\n",
    "        else:\n",
    "            FP+=1\n",
    "\n",
    "    accuracy_score = (TP+TN)*100/(TP+FP+FN+TN)\n",
    "    return accuracy_score\n",
    "# accuracy = test_perceptron(X_test, y_test, w_weight)    \n",
    "# print(\"Accuracy: \", accuracy, \"%\")\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "80% Training 20% Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  100.0 %\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, shuffle=True)\n",
    "w_weight = train_perceptron(X_train, y_train, w_weight)\n",
    "accuracy = test_perceptron(X_test, y_test, w_weight)    \n",
    "print(\"Accuracy: \", accuracy, \"%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "70% Training 30% Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  90.0 %\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, shuffle=True)\n",
    "w_weight = train_perceptron(X_train, y_train, w_weight)\n",
    "accuracy = test_perceptron(X_test, y_test, w_weight)    \n",
    "print(\"Accuracy: \", accuracy, \"%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "60% Training 40% Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  85.71428571428571 %\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.4, shuffle=True)\n",
    "w_weight = train_perceptron(X_train, y_train, w_weight)\n",
    "accuracy = test_perceptron(X_test, y_test, w_weight)    \n",
    "print(\"Accuracy: \", accuracy, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classwise Train and Test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_perceptron(features, labels, w_weight):\n",
    "    input_size = len(features)\n",
    "    new_weights = w_weight\n",
    "    for i in range(input_size):\n",
    "        weighted_output = weighted_sum(features[i], new_weights)\n",
    "        activated_output = step(weighted_output, threshold)\n",
    "        error = labels[i] - activated_output\n",
    "        # print(error)\n",
    "        if error!=0:\n",
    "            new_weights = adapt_weight(features[i], new_weights, error)\n",
    "            # print(new_weights)\n",
    "            \n",
    "            i = len(features)//2\n",
    "\n",
    "        \n",
    "            \n",
    "    return new_weights\n",
    "\n",
    "w_weight = train_perceptron(X_train, y_train, w_weight)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the model and evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  85.71428571428571 %\n"
     ]
    }
   ],
   "source": [
    "def test_perceptron(features, labels, w_weight):\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    \n",
    "    input_size = len(features)\n",
    "    new_weights = w_weight\n",
    "    for i in range(input_size):\n",
    "        weighted_output = weighted_sum(features[i], new_weights)\n",
    "        activated_output = step(weighted_output, threshold)\n",
    "\n",
    "        if activated_output == 0 and labels[i] == 0:\n",
    "            TN+=1\n",
    "        elif activated_output == 1 and labels[i] == 1:\n",
    "            TP+=1\n",
    "        elif activated_output == 0 and labels[i] == 1:\n",
    "            FN+=1\n",
    "        else:\n",
    "            FP+=1\n",
    "\n",
    "    accuracy_score = (TP+TN)*100/(TP+FP+FN+TN)\n",
    "    return accuracy_score\n",
    "accuracy = test_perceptron(X_test, y_test, w_weight)    \n",
    "print(\"Accuracy: \", accuracy, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d3e10ef16274dd72e574b8fa73b58450b957d8421a2901baded3cca26fcf5dda"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
